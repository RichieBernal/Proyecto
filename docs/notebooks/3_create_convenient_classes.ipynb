{"cells":[{"cell_type":"code","execution_count":18,"metadata":{"id":"aqyoDIrmbA4O"},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","\n","\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"elp0Ya-qbA4T"},"outputs":[],"source":["DATASETS_DIR = './data/'\n","URL = 'C:/Users/rbernal/Documents/GitHub/Proyecto/FAE/data/data_fire.csv'\n","RETRIEVED_DATA = 'data_fire.csv'\n","\n","\n","SEED_SPLIT = 404\n","TRAIN_DATA_FILE = DATASETS_DIR + 'train.csv'\n","TEST_DATA_FILE  = DATASETS_DIR + 'test.csv'\n","\n","TARGET  = 'STATUS'\n","FEATURES = ['SIZE','FUEL','DISTANCE','DESIBEL','AIRFLOW','FREQUENCY']\n","CATEGORICAL_VARS = ['FUEL']\n","NUMERICAL_VARS = ['SIZE','DISTANCE','DESIBEL','AIRFLOW','FREQUENCY']\n","\n","SEED_MODEL = 404"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"oAtmWQjnbA4U"},"outputs":[],"source":["def retrieve_data(self):\n","\n","# Loading data from specific path\n","    data = pd.read_csv(url) \n","\n","    # Create directory if it does not exist\n","    if not os.path.exists(self.DATASETS_DIR):\n","            os.makedirs(self.DATASETS_DIR)\n","            print(f\"Directory '{self.DATASETS_DIR}' created successfully.\")\n","        else:\n","            print(f\"Directory '{self.DATASETS_DIR}' already exists.\")\n","\n","    # Save data to CSV file\n","    data.to_csv(self.DATASETS_DIR + self.RETRIEVED_DATA, index=False)\n","\n","    return f'Data stored in {self.DATASETS_DIR + self.RETRIEVED_DATA}'"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"ttJd7QySbA4W"},"outputs":[],"source":["df = pd.read_csv(DATASETS_DIR + RETRIEVED_DATA)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"f6bzhGmabA4X"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(\n","                                                        df.drop(TARGET, axis=1),\n","                                                        df[TARGET],\n","                                                        test_size=0.2,\n","                                                        random_state=404\n","                                                   )\n","\n","X_train.to_csv(TRAIN_DATA_FILE, index=False)\n","X_test.to_csv(TEST_DATA_FILE, index=False)\n","y_test.to_csv('y_test.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"qL7qPTdGbA4Y"},"source":["___\n","## Creating convenient classes"]},{"cell_type":"markdown","metadata":{"id":"0wH0G8pabA4Z"},"source":["### Transformations without persisting information"]},{"cell_type":"markdown","metadata":{"id":"QeLovJBRbA4d"},"source":["**Before**\n","\n","```python\n","X_train = pd.concat([X_train, pd.get_dummies(X_train[CATEGORICAL_VARS], drop_first=True)], 1)\n","X_test  = pd.concat([X_test, pd.get_dummies(X_test[CATEGORICAL_VARS], drop_first=True)], 1)\n","\n","X_train.drop(CATEGORICAL_VARS, 1, inplace=True)\n","X_test.drop(CATEGORICAL_VARS, 1, inplace=True)\n","\n","# Validation step\n","set(X_train.columns).difference(set(X_test.columns))\n","\n","for col in list(set(X_train.columns).difference(set(X_test.columns))):\n","    X_test[col] = 0\n","```\n","\n","**Now**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class OneHotEncoder(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, variables=None):\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        self.dummies = pd.get_dummies(X[self.variables], drop_first=True).columns\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        X = pd.concat([X, pd.get_dummies(X[self.variables], drop_first=True)], axis=1)\n","        X.drop(self.variables, axis=1)\n","\n","        # Adding missing dummies, if any\n","        missing_dummies = [var for var in self.dummies if var not in X.columns]\n","        if len(missing_dummies) != 0:\n","            for col in missing_dummies:\n","                X[col] = 0\n","\n","        return X\n","\n","\n","dummy_vars = OneHotEncoder(variables=CATEGORICAL_VARS)\n","dummy_vars.fit(X_train)\n","X_train = dummy_vars.transform(X_train)\n","X_test  = dummy_vars.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"Pkk-hcxBbA4e"},"source":["**Aligning columns of X_train and X_test**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ylkHn_BpbA4e"},"outputs":[],"source":["class OrderingFeatures(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        return None\n","\n","    def fit(self, X, y=None):\n","        self.ordered_features = X.columns\n","        return self\n","\n","    def transform(self, X):\n","        return X[self.ordered_features]\n","\n","\n","sort_feats = OrderingFeatures()\n","sort_feats.fit(X_train)\n","X_train = sort_feats.transform(X_train)\n","X_test  = sort_feats.transform(X_test)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
